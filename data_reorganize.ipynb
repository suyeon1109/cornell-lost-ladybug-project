{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD8Q9S79EBMkaPSZ3xMf5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyeon1109/cornell-lost-ladybug-project/blob/main/data_reorganize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import TextVectorization, CategoryEncoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load your CSV data into a DataFrame (replace this with your data loading code)\n",
        "data1 = pd.read_csv('/content/train (1).csv')\n",
        "data2 = pd.read_csv('/content/test.csv')\n",
        "data = pd.concat([data1, data2], axis=0)\n",
        "data = data.reset_index(drop=True)\n",
        "# train.stack(data2, level=-1, dropna=True)\n",
        "\n",
        "# data['array'] = data['array'].str.replace('.', ',')\n",
        "# data['array'] = data['array'].str.replace('\\n', ',')\n",
        "# data['array'] = data['array'].str.replace(',,', '..')\n",
        "# data['array'] = data['array'].str.replace(',,,', '...')\n",
        "# data['array'] = data['array'].str.replace(',,,,', '....')\n",
        "# data['array'] = data['array'].str.replace(',,,,,', '.....')\n",
        "# data['array'][0]"
      ],
      "metadata": {
        "id": "mpCEptOdz0mg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Preprocess the 'stateName' column using tokenization and padding\n",
        "max_words = 1000  # Maximum number of words to consider\n",
        "max_sequence_length = 10  # Maximum length of a sequence\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')  # <OOV> for out-of-vocabulary words\n",
        "tokenizer.fit_on_texts(data['stateName'])\n",
        "sequences = tokenizer.texts_to_sequences(data['stateName'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# # Separate features and labels\n",
        "# features = padded_sequences\n",
        "# labels = data['target_column']"
      ],
      "metadata": {
        "id": "MDAb8QiDV0_V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('Unnamed: 0.1', axis=1)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTPQ_yZvAnO2",
        "outputId": "02f65b00-117c-40e2-a1f1-0ad0b75d0a45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7659 entries, 0 to 7658\n",
            "Data columns (total 40 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Unnamed: 0                7659 non-null   int64  \n",
            " 1   imageFileName             7659 non-null   object \n",
            " 2   array                     7659 non-null   object \n",
            " 3   photoSubmissionID         7659 non-null   int64  \n",
            " 4   speciesName               7659 non-null   object \n",
            " 5   isGuess                   7659 non-null   object \n",
            " 6   photoQuality              7659 non-null   object \n",
            " 7   year                      7659 non-null   int64  \n",
            " 8   stateName                 7659 non-null   object \n",
            " 9   countyName                7659 non-null   object \n",
            " 10  tribalLand                7659 non-null   object \n",
            " 11  latitude                  7659 non-null   object \n",
            " 12  longitude                 7659 non-null   object \n",
            " 13  spotterNumber             7659 non-null   int64  \n",
            " 14  habitatName               7659 non-null   object \n",
            " 15  searchHours               7659 non-null   float64\n",
            " 16  timeOfDay                 7659 non-null   object \n",
            " 17  searchPlanned             7659 non-null   object \n",
            " 18  method                    7659 non-null   object \n",
            " 19  weather                   7659 non-null   object \n",
            " 20  temperature               7659 non-null   object \n",
            " 21  foundBugs                 7659 non-null   object \n",
            " 22  hasplant                  7659 non-null   object \n",
            " 23  Educational: egg          7659 non-null   object \n",
            " 24  Educational: prey         7659 non-null   object \n",
            " 25  Educational: larva        7659 non-null   object \n",
            " 26  Educational: aggregation  7659 non-null   object \n",
            " 27  Educational: pupa         7659 non-null   object \n",
            " 28  Educational: not ladybug  7659 non-null   object \n",
            " 29  Other: kids               7659 non-null   object \n",
            " 30  Other: story              7659 non-null   object \n",
            " 31  Other: rare               7659 non-null   object \n",
            " 32  Other: out NAm            7659 non-null   object \n",
            " 33  Other: Host Plant ID      7659 non-null   object \n",
            " 34  Source: Kids              7659 non-null   object \n",
            " 35  Source: Youth (14-23)     7659 non-null   object \n",
            " 36  Source: Adult             7659 non-null   object \n",
            " 37  Source: Group             7659 non-null   object \n",
            " 38  Source: Family            7659 non-null   object \n",
            " 39  index                     7659 non-null   float64\n",
            "dtypes: float64(2), int64(4), object(34)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through columns with string values and convert them to int64\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':  # Check if column contains string values\n",
        "        data[column] = data[column].astype('int64', errors='ignore')"
      ],
      "metadata": {
        "id": "IJWy3sheX28O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS6tja2aYAXf",
        "outputId": "b6c94030-15f0-49c9-cfd8-f359e4481ebe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7659 entries, 0 to 7658\n",
            "Data columns (total 40 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Unnamed: 0                7659 non-null   int64  \n",
            " 1   imageFileName             7659 non-null   object \n",
            " 2   array                     7659 non-null   object \n",
            " 3   photoSubmissionID         7659 non-null   int64  \n",
            " 4   speciesName               7659 non-null   object \n",
            " 5   isGuess                   7659 non-null   object \n",
            " 6   photoQuality              7659 non-null   object \n",
            " 7   year                      7659 non-null   int64  \n",
            " 8   stateName                 7659 non-null   object \n",
            " 9   countyName                7659 non-null   object \n",
            " 10  tribalLand                7659 non-null   object \n",
            " 11  latitude                  7659 non-null   object \n",
            " 12  longitude                 7659 non-null   object \n",
            " 13  spotterNumber             7659 non-null   int64  \n",
            " 14  habitatName               7659 non-null   object \n",
            " 15  searchHours               7659 non-null   float64\n",
            " 16  timeOfDay                 7659 non-null   object \n",
            " 17  searchPlanned             7659 non-null   object \n",
            " 18  method                    7659 non-null   object \n",
            " 19  weather                   7659 non-null   object \n",
            " 20  temperature               7659 non-null   object \n",
            " 21  foundBugs                 7659 non-null   object \n",
            " 22  hasplant                  7659 non-null   object \n",
            " 23  Educational: egg          7659 non-null   object \n",
            " 24  Educational: prey         7659 non-null   object \n",
            " 25  Educational: larva        7659 non-null   object \n",
            " 26  Educational: aggregation  7659 non-null   object \n",
            " 27  Educational: pupa         7659 non-null   object \n",
            " 28  Educational: not ladybug  7659 non-null   object \n",
            " 29  Other: kids               7659 non-null   object \n",
            " 30  Other: story              7659 non-null   object \n",
            " 31  Other: rare               7659 non-null   object \n",
            " 32  Other: out NAm            7659 non-null   object \n",
            " 33  Other: Host Plant ID      7659 non-null   object \n",
            " 34  Source: Kids              7659 non-null   object \n",
            " 35  Source: Youth (14-23)     7659 non-null   object \n",
            " 36  Source: Adult             7659 non-null   object \n",
            " 37  Source: Group             7659 non-null   object \n",
            " 38  Source: Family            7659 non-null   object \n",
            " 39  index                     7659 non-null   float64\n",
            "dtypes: float64(2), int64(4), object(34)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import preprocessing\n",
        "\n",
        "load = load_iris()\n",
        "\n",
        "# separate the independent and dependent variables\n",
        "X_data = load.data\n",
        "target = load.target\n",
        "\n",
        "# standardization of dependent variables\n",
        "standard = preprocessing.scale(X_data)\n",
        "print(standard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4sn8SC4Yy_g",
        "outputId": "74b5ca4a-aeff-4e8c-9d98-0c97b807e47d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00 -1.31979479e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.24920112e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.16971425e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  7.88807586e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.44707648e+00]\n",
            " [-5.37177559e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.87002413e+00 -1.31979479e-01 -1.51073881e+00 -1.44707648e+00]\n",
            " [-5.25060772e-02  2.16998818e+00 -1.45390138e+00 -1.31544430e+00]\n",
            " [-1.73673948e-01  3.09077525e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00]\n",
            " [-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.73673948e-01  1.70959465e+00 -1.16971425e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.28338910e+00 -1.18381211e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.16971425e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  1.47939788e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  5.58610819e-01 -1.16971425e+00 -9.20547742e-01]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00 -1.31979479e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  1.01900435e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-7.79513300e-01  7.88807586e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  9.82172869e-02 -1.22655167e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.28338910e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  2.40018495e+00 -1.28338910e+00 -1.44707648e+00]\n",
            " [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  3.28414053e-01 -1.45390138e+00 -1.31544430e+00]\n",
            " [-4.16009689e-01  1.01900435e+00 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.74885626e+00 -1.31979479e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.62768839e+00 -1.74335684e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.74885626e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.22655167e+00 -7.88915558e-01]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  3.28414053e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-6.58345429e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  5.58610819e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [ 1.40150837e+00  3.28414053e-01  5.35408562e-01  2.64141916e-01]\n",
            " [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  6.49083415e-01  3.95774101e-01]\n",
            " [-4.16009689e-01 -1.74335684e+00  1.37546573e-01  1.32509732e-01]\n",
            " [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  4.21733708e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  5.35408562e-01  5.27406285e-01]\n",
            " [-1.14301691e+00 -1.51316008e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [ 9.16836886e-01 -3.62176246e-01  4.78571135e-01  1.32509732e-01]\n",
            " [-7.79513300e-01 -8.22569778e-01  8.07091462e-02  2.64141916e-01]\n",
            " [-1.02184904e+00 -2.43394714e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [ 6.86617933e-02 -1.31979479e-01  2.51221427e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01]\n",
            " [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -3.62176246e-01 -8.98031345e-02  1.32509732e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  3.64896281e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  1.94384000e-01 -2.62386821e-01]\n",
            " [ 4.32165405e-01 -1.97355361e+00  4.21733708e-01  3.95774101e-01]\n",
            " [-2.94841818e-01 -1.28296331e+00  8.07091462e-02 -1.30754636e-01]\n",
            " [ 6.86617933e-02  3.28414053e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01 -1.28296331e+00  6.49083415e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04]\n",
            " [ 6.74501145e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [ 9.16836886e-01 -1.31979479e-01  3.64896281e-01  2.64141916e-01]\n",
            " [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01]\n",
            " [ 1.03800476e+00 -1.31979479e-01  7.05920842e-01  6.59038469e-01]\n",
            " [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -1.05276654e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00  2.38717193e-02 -1.30754636e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00 -3.29657076e-02 -2.62386821e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  8.07091462e-02  8.77547895e-04]\n",
            " [ 1.89829664e-01 -8.22569778e-01  7.62758269e-01  5.27406285e-01]\n",
            " [-5.37177559e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01  7.88807586e-01  4.21733708e-01  5.27406285e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01]\n",
            " [ 5.53333275e-01 -1.74335684e+00  3.64896281e-01  1.32509732e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  1.94384000e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.28296331e+00  1.37546573e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04]\n",
            " [ 3.10997534e-01 -1.31979479e-01  4.78571135e-01  2.64141916e-01]\n",
            " [-5.25060772e-02 -1.05276654e+00  1.37546573e-01  8.77547895e-04]\n",
            " [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [-2.94841818e-01 -8.22569778e-01  2.51221427e-01  1.32509732e-01]\n",
            " [-1.73673948e-01 -1.31979479e-01  2.51221427e-01  8.77547895e-04]\n",
            " [-1.73673948e-01 -3.62176246e-01  2.51221427e-01  1.32509732e-01]\n",
            " [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [-9.00681170e-01 -1.28296331e+00 -4.30827696e-01 -1.30754636e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  1.94384000e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.52267624e+00 -1.31979479e-01  1.21745768e+00  1.18556721e+00]\n",
            " [ 5.53333275e-01 -3.62176246e-01  1.04694540e+00  7.90670654e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  1.16062026e+00  1.31719939e+00]\n",
            " [ 2.12851559e+00 -1.31979479e-01  1.61531967e+00  1.18556721e+00]\n",
            " [-1.14301691e+00 -1.28296331e+00  4.21733708e-01  6.59038469e-01]\n",
            " [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01]\n",
            " [ 1.03800476e+00 -1.28296331e+00  1.16062026e+00  7.90670654e-01]\n",
            " [ 1.64384411e+00  1.24920112e+00  1.33113254e+00  1.71209594e+00]\n",
            " [ 7.95669016e-01  3.28414053e-01  7.62758269e-01  1.05393502e+00]\n",
            " [ 6.74501145e-01 -8.22569778e-01  8.76433123e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00 -1.31979479e-01  9.90107977e-01  1.18556721e+00]\n",
            " [-1.73673948e-01 -1.28296331e+00  7.05920842e-01  1.05393502e+00]\n",
            " [-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00]\n",
            " [ 6.74501145e-01  3.28414053e-01  8.76433123e-01  1.44883158e+00]\n",
            " [ 7.95669016e-01 -1.31979479e-01  9.90107977e-01  7.90670654e-01]\n",
            " [ 2.24968346e+00  1.70959465e+00  1.67215710e+00  1.31719939e+00]\n",
            " [ 2.24968346e+00 -1.05276654e+00  1.78583195e+00  1.44883158e+00]\n",
            " [ 1.89829664e-01 -1.97355361e+00  7.05920842e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  3.28414053e-01  1.10378283e+00  1.44883158e+00]\n",
            " [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00]\n",
            " [ 2.24968346e+00 -5.92373012e-01  1.67215710e+00  1.05393502e+00]\n",
            " [ 5.53333275e-01 -8.22569778e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00  3.28414053e-01  1.27429511e+00  7.90670654e-01]\n",
            " [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -1.31979479e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00 -1.31979479e-01  1.16062026e+00  5.27406285e-01]\n",
            " [ 1.88617985e+00 -5.92373012e-01  1.33113254e+00  9.22302838e-01]\n",
            " [ 2.49201920e+00  1.70959465e+00  1.50164482e+00  1.05393502e+00]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.31719939e+00]\n",
            " [ 5.53333275e-01 -5.92373012e-01  7.62758269e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01]\n",
            " [ 2.24968346e+00 -1.31979479e-01  1.33113254e+00  1.44883158e+00]\n",
            " [ 5.53333275e-01  7.88807586e-01  1.04694540e+00  1.58046376e+00]\n",
            " [ 6.74501145e-01  9.82172869e-02  9.90107977e-01  7.90670654e-01]\n",
            " [ 1.89829664e-01 -1.31979479e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  9.33270550e-01  1.18556721e+00]\n",
            " [ 1.03800476e+00  9.82172869e-02  1.04694540e+00  1.58046376e+00]\n",
            " [ 1.28034050e+00  9.82172869e-02  7.62758269e-01  1.44883158e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00  3.28414053e-01  1.21745768e+00  1.44883158e+00]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.71209594e+00]\n",
            " [ 1.03800476e+00 -1.31979479e-01  8.19595696e-01  1.44883158e+00]\n",
            " [ 5.53333275e-01 -1.28296331e+00  7.05920842e-01  9.22302838e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  8.19595696e-01  1.05393502e+00]\n",
            " [ 4.32165405e-01  7.88807586e-01  9.33270550e-01  1.44883158e+00]\n",
            " [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCkMRnsDZVOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string values in 'array' column to numpy arrays\n",
        "for idx, row in data.iterrows():\n",
        "    string_array = row['array']  # Get the string value from the 'array' column\n",
        "    numpy_array = np.fromstring(string_array[1:-1], sep=',', dtype=np.float32)  # Convert to numpy array\n",
        "    data.at[idx, 'array'] = numpy_array  # Update the DataFrame with the numpy array\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval  # Used to convert string list to actual list\n",
        "\n",
        "# Convert the string list column to actual lists\n",
        "data['stateName'] = data['stateName'].apply(lambda x: literal_eval(x))\n",
        "\n",
        "# Separate features and labels\n",
        "features = data.drop('array', axis=1)\n",
        "labels = data['array']\n",
        "\n",
        "# Convert string categories to numerical labels if needed\n",
        "# Example: if 'target_column' contains string labels\n",
        "# labels = pd.Categorical(labels).codes\n",
        "\n",
        "# Convert the list column to numpy arrays\n",
        "list_column_array = np.array(features['array'].tolist())\n",
        "\n",
        "# Drop the original list column from features\n",
        "features = features.drop('array', axis=1)\n",
        "\n",
        "# Convert categorical variables to one-hot encodings if needed\n",
        "# features = pd.get_dummies(features, columns=['categorical_column'])\n",
        "\n",
        "# Create the Keras model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(features.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Change activation based on your problem\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(features, labels, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "IxnnAL9S81tB",
        "outputId": "6d4c3893-a0df-4880-f874-00a8f2f81ec3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-807a7499d96e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Convert the string list column to actual lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stateName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stateName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-807a7499d96e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Convert the string list column to actual lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stateName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stateName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlno\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lineno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' on line {lno}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf': {node!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: malformed node or string on line 1: <ast.Name object at 0x7d7638b5dea0>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['array']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR3UzbW28PLI",
        "outputId": "c726d777-e8db-46fb-f96c-a32600cb6596"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[[115. 102. 112.]\\n  [110. 110. 108.]\\n  [ 50...\n",
              "1       [[[ 77.  89.  85.]\\n  [ 85.  96.  98.]\\n  [ 96...\n",
              "2       [[[119. 154.  70.]\\n  [124. 162.  75.]\\n  [116...\n",
              "3       [[[ 69.  47.  34.]\\n  [ 69.  47.  34.]\\n  [ 69...\n",
              "4       [[[108.  73.  31.]\\n  [113.  72.  42.]\\n  [107...\n",
              "                              ...                        \n",
              "7654    [[[185. 208. 226.]\\n  [222. 235. 244.]\\n  [253...\n",
              "7655    [[[184. 133. 130.]\\n  [186. 135. 132.]\\n  [185...\n",
              "7656    [[[168. 186. 208.]\\n  [164. 182. 204.]\\n  [167...\n",
              "7657    [[[105.  73.  52.]\\n  [107.  75.  54.]\\n  [103...\n",
              "7658    [[[ 95. 123.  38.]\\n  [ 86. 114.  29.]\\n  [ 88...\n",
              "Name: array, Length: 7659, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval  # Used to convert string list to actual list\n",
        "\n",
        "# Convert the string list column to actual lists\n",
        "data['countyName'] = data['countyName'].apply(lambda x: literal_eval(x))\n",
        "\n",
        "# Separate features and labels\n",
        "features = data.drop('array', axis=1)\n",
        "labels = data['array']\n",
        "\n",
        "# Convert string categories to numerical labels if needed\n",
        "# Example: if 'target_column' contains string labels\n",
        "# labels = pd.Categorical(labels).codes\n",
        "\n",
        "# Convert the list column to numpy arrays\n",
        "list_column_array = np.array(features['array'].tolist())\n",
        "\n",
        "# Drop the original list column from features\n",
        "features = features.drop('array', axis=1)\n",
        "\n",
        "# Convert categorical variables to one-hot encodings if needed\n",
        "# features = pd.get_dummies(features, columns=['categorical_column'])\n",
        "\n",
        "# Create the Keras model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(features.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Change activation based on your problem\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(features, labels, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "MJpUQ50qRI3T",
        "outputId": "f1f3f4b0-870b-4de1-ccd7-b75a641acf6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0d429fa41827>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the string list column to actual lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countyName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countyName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0d429fa41827>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the string list column to actual lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countyName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countyName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlno\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lineno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' on line {lno}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf': {node!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: malformed node or string on line 1: <ast.Name object at 0x7d7638b5f5e0>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "9Fj_GXi79hzT",
        "outputId": "8beb4f0d-9f53-4e2a-8a90-c74cc328e39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-106-d24715030fbf>:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['array'] = data['array'].str.replace('.', ',')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-d24715030fbf>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mformatted_array_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mformatted_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert numpy array to list and then to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mformatted_array_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tolist'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import TextVectorization, CategoryEncoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load your CSV data into a DataFrame (replace this with your data loading code)\n",
        "data1 = pd.read_csv('/train (1).csv')\n",
        "data2 = pd.read_csv('/test.csv')\n",
        "data = pd.concat([data1, data2], axis=0)\n",
        "data = data.reset_index(drop=True)\n",
        "# train.stack(data2, level=-1, dropna=True)\n",
        "\n",
        "data['array'] = data['array'].str.replace('.', ',')\n",
        "data['array'] = data['array'].str.replace('\\n', ',')\n",
        "\n",
        "data['array'] = data['array'].str.replace(',,', '..')\n",
        "data['array'] = data['array'].str.replace(',,,', '...')\n",
        "data['array'] = data['array'].str.replace(',,,,', '....')\n",
        "data['array'] = data['array'].str.replace(',,,,,', '.....')\n",
        "data['array'][0]\n",
        "\n",
        "# Identify object and string columns you want to convert\n",
        "# obj_to_str_columns = ['imageFileName', 'speciesName', 'isGuess', 'photoQuality',\n",
        "#        'stateName', 'countyName', 'tribalLand','habitatName', 'timeOfDay',\n",
        "#        'searchPlanned', 'method', 'weather', 'foundBugs', 'hasplant',\n",
        "#        'Educational: egg', 'Educational: prey', 'Educational: larva',\n",
        "#        'Educational: aggregation', 'Educational: pupa', 'Educational: not ladybug',\n",
        "#        'Other: kids', 'Other: story', 'Other: rare', 'Other: out NAm',\n",
        "#        'Other: Host Plant ID', 'Source: Kids', 'Source: Youth (14-23)',\n",
        "#        'Source: Adult', 'Source: Group','Source: Family', 'latitude',\n",
        "#        'longitude', 'temperature']\n",
        "\n",
        "str_to_int_columns = ['latitude', 'longitude', 'temperature']\n",
        "\n",
        "# object_columns = data.select_dtypes(include=['object'])\n",
        "\n",
        "# for column_name in obj_to_str_columns:\n",
        "#     data[column_name] = pd.factorize(data[column_name])[0].astype(str)\n",
        "\n",
        "for each in str_to_int_columns:\n",
        "    data[each] = pd.to_numeric(data[each], errors='coerce').astype('Float64')\n",
        "\n",
        "\n",
        "# object_columns = data.select_dtypes(include=['object'])\n",
        "\n",
        "# for column_name in object_columns:\n",
        "#     counter = 0\n",
        "#     for unique_value in data[column_name].unique().tolist():\n",
        "#         data.loc[data[column_name] == unique_value, column_name] = str(counter)\n",
        "#         counter += 1\n",
        "'''\n",
        " :\n",
        "1. array column  \n",
        "'''\n",
        "\n",
        "# Convert numpy array values to formatted strings\n",
        "formatted_array_data = []\n",
        "for array in data['array']:\n",
        "    formatted_array = array.tolist()  # Convert numpy array to list and then to string\n",
        "    formatted_array_data.append(formatted_array)\n",
        "\n",
        "# Update the 'array' column in the DataFrame with formatted values\n",
        "data['array'] = formatted_array_data\n",
        "\n",
        "# Save the DataFrame back to the CSV file\n",
        "data.to_csv('updated_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['array']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ-pu2Z112fV",
        "outputId": "a8c03908-ca13-4c7c-b3bc-c3b9a1a3597b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[[115, 102, 112,],  [110, 110, 108,],  [ 50, ...\n",
              "1       [[[ 77,  89,  85,],  [ 85,  96,  98,],  [ 96, ...\n",
              "2       [[[119, 154,  70,],  [124, 162,  75,],  [116, ...\n",
              "3       [[[ 69,  47,  34,],  [ 69,  47,  34,],  [ 69, ...\n",
              "4       [[[108,  73,  31,],  [113,  72,  42,],  [107, ...\n",
              "                              ...                        \n",
              "6067    [[[102, 111, 126,],  [ 94, 103, 118,],  [ 93, ...\n",
              "6068    [[[169, 113, 116,],  [167, 111, 114,],  [183, ...\n",
              "6069    [[[201, 184, 164,],  [202, 185, 165,],  [198, ...\n",
              "6070    [[[210, 151, 153,],  [201, 142, 144,],  [200, ...\n",
              "6071    [[[184, 150, 148,],  [184, 150, 148,],  [183, ...\n",
              "Name: array, Length: 6072, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval\n",
        "\n",
        "# # Load CSV data into a DataFrame\n",
        "# csv_file_path = '/train (1).csv'  # Replace with the actual file path\n",
        "# data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Add a vacant column (replace 'new_column_name' with the desired column name)\n",
        "data['label'] = ''\n",
        "# Save the DataFrame back to the CSV file\n",
        "data.to_csv('updated_data.csv', index=False)\n",
        "\n",
        "# Define other parameters\n",
        "sample_num = 22\n",
        "\n",
        "# Preprocess data\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    # Process image data (assuming image array column name is 'array')\n",
        "    img_array = literal_eval(row['array'])\n",
        "\n",
        "    # Process string data (assuming string column name is 'speciesName')\n",
        "    string_value = row['speciesName']\n",
        "    categorical_value = label_encoder.fit_transform([string_value])[0]\n",
        "\n",
        "    # Combine all processed features into a single input vector\n",
        "    input_vector = [img_array, categorical_value]\n",
        "\n",
        "    images.append(input_vector)\n",
        "    labels.append(row['label'])  # Assuming you have a 'label' column in your CSV\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Shuffle the data\n",
        "images, labels = shuffle(images, labels)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(images.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(label_encoder.classes_.shape[0], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=100)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, to_categorical(y_test))\n",
        "print('test_acc:', test_acc)\n",
        "print('test_loss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "zXQgOKRQXr50",
        "outputId": "6f033baa-b435-4824-9a81-8c4f1a1bd96e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-e320bd607eaf>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval\n",
        "\n",
        "# Load CSV data into a DataFrame\n",
        "csv_file_path = '/train (1).csv'  # Replace with the actual file path\n",
        "data = pd.read_csv(csv_file_path)\n",
        "# Add a vacant column (replace 'new_column_name' with the desired column name)\n",
        "data['label'] = ''\n",
        "# Save the DataFrame back to the CSV file\n",
        "data.to_csv('updated_data.csv', index=False)\n",
        "\n",
        "# Define other parameters\n",
        "sample_num = 22\n",
        "\n",
        "# Preprocess data\n",
        "label_encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    # Process image data (assuming image array column name is 'array')\n",
        "    # img_array = ast.literal_eval(row['array'][1:-1], sep=',')\n",
        "    img_array = literal_eval(row['array'])\n",
        "\n",
        "    # Process string data (assuming string column name is 'speciesName')\n",
        "    string_value = row['speciesName']\n",
        "    categorical_value = label_encoder.fit_transform([string_value])[0]\n",
        "\n",
        "    # Process float data (assuming float column name is 'longitude')\n",
        "    # float_value = row['longitude']\n",
        "    # scaled_float = scaler.fit_transform(np.array([[float_value]]))\n",
        "\n",
        "    # Combine all processed features into a single input vector\n",
        "    input_vector = np.concatenate([img_array, [categorical_value], scaled_float.flatten()])\n",
        "\n",
        "    images.append(input_vector)\n",
        "    labels.append(row['label'])  # Assuming you have a 'label' column in your CSV\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Shuffle the data\n",
        "images, labels = shuffle(images, labels)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(images.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(label_encoder.classes_.shape[0], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=100)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, to_categorical(y_test))\n",
        "print('test_acc:', test_acc)\n",
        "print('test_loss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "-Ngsf_cYEAQj",
        "outputId": "f9ffa82e-654a-4da4-a68b-72603146f29d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-9-9c53f8eec488>\"\u001b[0m, line \u001b[1;32m33\u001b[0m, in \u001b[1;35m<cell line: 30>\u001b[0m\n    img_array = literal_eval(row['array'])\n",
            "  File \u001b[1;32m\"/usr/lib/python3.10/ast.py\"\u001b[0m, line \u001b[1;32m64\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.10/ast.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [[[115. 102. 112.]\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.utils as image\n",
        "\n",
        "\n",
        "\n",
        "# Load CSV data into a DataFrame\n",
        "csv_file_path = '/content/train (1).csv'  # Replace with the actual file path\n",
        "data = pd.read_csv(csv_file_path)\n",
        "# Add a vacant column (replace 'new_column_name' with the desired column name)\n",
        "data['label'] = ''\n",
        "# Save the DataFrame back to the CSV file\n",
        "data.to_csv('updated_data.csv', index=False)\n",
        "\n",
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the paths to your dataset folders and other parameters\n",
        "data_dir = '/content/train (1).csv'\n",
        "train_ratio = 0.8\n",
        "image_size = (224, 224)  # Adjust the image size as needed\n",
        "sample_num = 1000\n",
        "\n",
        "# Create a dictionary to map label names to numeric labels\n",
        "label_mapping = {}\n",
        "label_counter = 0\n",
        "\n",
        "# Initialize empty lists to store images and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Iterate through each subfolder (label) in the dataset directory\n",
        "for label in os.listdir(data_dir):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "\n",
        "    # Check if the label folder has at least 111 images\n",
        "    if len(os.listdir(label_dir)) >= sample_num:\n",
        "        image_paths = os.listdir(label_dir)\n",
        "\n",
        "        # If there are more than 112 images, randomly select 112 images\n",
        "        if len(image_paths) > sample_num:\n",
        "            image_paths = random.sample(image_paths, sample_num)\n",
        "\n",
        "        # Assign a numeric label and update the mapping\n",
        "        if label not in label_mapping:\n",
        "            label_mapping[label] = label_counter\n",
        "            label_counter += 1\n",
        "\n",
        "        numeric_label = label_mapping[label]\n",
        "\n",
        "        # Calculate the number of images for training and testing\n",
        "        num_train = int(len(image_paths) * train_ratio)\n",
        "\n",
        "        # Iterate through the selected image paths\n",
        "        for idx, img_path in enumerate(image_paths):\n",
        "            img = image.load_img(os.path.join(label_dir, img_path), target_size=image_size)\n",
        "            img_array = image.img_to_array(img)\n",
        "            img_array = img_array / 255.0  # Normalize pixel values\n",
        "\n",
        "            if idx < num_train:\n",
        "                train_images.append(img_array)\n",
        "                train_labels.append(numeric_label)\n",
        "            else:\n",
        "                test_images.append(img_array)\n",
        "                test_labels.append(numeric_label)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# (1)  \n",
        "#     \n",
        "network = Sequential()\n",
        "network.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "network.add(MaxPooling2D((2, 2)))\n",
        "network.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "network.add(MaxPooling2D((2, 2)))\n",
        "network.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "network.add(Flatten())\n",
        "network.add(Dense(label_counter, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# (3)   ()\n",
        "network.fit(train_images, to_categorical(train_labels), epochs=10, batch_size=100)\n",
        "\n",
        "# (4)  ( )\n",
        "test_loss, test_acc = network.evaluate(test_images, to_categorical(test_labels))\n",
        "print('test_acc:', test_acc)\n",
        "print('test_loss:', test_loss)\n",
        "\n",
        "# Visualize misclassified samples\n",
        "for x in range(500):\n",
        "    image = test_images[x, :].reshape(1, 224, 224, 3)\n",
        "    prediction = network.predict(image).argmax()\n",
        "    label = test_labels[x]\n",
        "    if prediction != label:\n",
        "        plt.title(\"Sample %d  Prediction: %d Label: %d\" % (x, prediction, label))\n",
        "        plt.imshow(image.reshape([224, 224, 3]), cmap=plt.get_cmap('gray_r'))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "jDAyzEFiP89x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}